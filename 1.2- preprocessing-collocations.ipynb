{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Master Informatique, parcours Data Mining\n",
    "\n",
    "### Carnets de note Python pour le cours de Text Mining\n",
    "\n",
    "Julien Velcin, laboratoire ERIC, Université Lyon 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prétraitements (partie 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques prétraitements à connaître\n",
    "\n",
    "- expressions réguières et nettoyages simples\n",
    "- segmentation en mots (*tokenization*)\n",
    "- mots-outils\n",
    "- stemming et lemmatisation\n",
    "- **n-grammes et collocations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Au-delà des mots : n-grammes et collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au lieu de traiter de termes composés d'un seul mot, on peut manipuler des séquences composées de *plusieurs* mots. En anglais, on parle parfois de **phrases**. On espère parvenir ainsi à trouver des termes correspondant à des *expressions* qui ont du sens.\n",
    "\n",
    "Notez qu'on se contentera ici de suites de mots contigus.\n",
    "\n",
    "Les séquences de mots peuvent être trouvées (et stockées) à l'aide d'algorithmes de programmation dynamique, par ex. celui des tableaux de suffixes (*suffix arrays*).\n",
    "\n",
    "Le principal avantage à utiliser des expressions est d'identifier le sens d'un terme de manière plus précise, càd de lever une partie de l'ambiguïté des mots qui prennent souvent différents sens en fonction du contexte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, un **bigramme** est une séquence de deux mots consécutifs, comme dans :\n",
    "\n",
    ">\"american president\"<br/>\n",
    ">\"world war\"<br/>\n",
    ">\"health care\"<br/>\n",
    ">\"bird is\"<br/>\n",
    ">\"the sleepy\"\n",
    "\n",
    "On obtient les bigrammes en glissant une fenêtre de 2 mots sur le texte. On peut bien sûr généraliser à des séquences de 3 mots (trigrammes) voire n mots (n-grammes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mots ou expressions ?\n",
    "\n",
    "Lewis (SIGIR, 1992) montre que les mots (1-gramme) ont des meilleures propriétés statistiques, en particulier pour la classification :\n",
    "\n",
    "- les mots apparaissent plusieurs fois dans les documents\n",
    "- les expressions n'apparaissent souvent qu'une seule fois\n",
    "\n",
    "Les expressions fournissent plus d'information sémantique tandis que les mots ont souvent plusieurs sens (polysémie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de calculer des n-grammes à l'aide de la librairie *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous reviendrons plus tard sur cette classe de la librairie scikit-learn :\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "with open(\"datasets/Frank Herbert - Dune.txt\", \"r\", encoding='utf8') as f:\n",
    "    texte_docs = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# range permet de spécifier la longueur des expressions considérées\n",
    "# min_df permet de régler la rareté des expressions\n",
    "vecto_bigrams = CountVectorizer(ngram_range=(2,2), min_df = 0)\n",
    "matrice_doc_big = vecto_bigrams.fit_transform(texte_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8608, 93241)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrice_doc_big.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer les n-grammes extraits grâce à la fonction *get_feature_names()* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000 kilos', '000 men', '000 meters', '000 solaris', '000 year', '023 per', '082 10', '092 10', '10 082', '10 092']\n"
     ]
    }
   ],
   "source": [
    "print([s for s in vecto_bigrams.get_feature_names()[0:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème est qu'on peut vite se retrouver submergé par les n-grammes.\n",
    "Il devient crucial de filtrer les expressions, par exemple en fixant un seuil sur le nombre d'occurrences minimal.\n",
    "\n",
    "Mais il existe d'autres moyens afin d'aller au-delà des n-grammes en cherchant les **collocations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une **collocation** est un groupe de mots qui ont développé une affinité particulière, de telle sorte à ce que les locuteurs les utilisent naturellement ensemble.\n",
    "\n",
    "Une collocation comme *\"New York City\"* prend tout son sens à partir du moment où les trois mots sont utilisés ensemble.\n",
    "\n",
    "D'autres exemples :\n",
    "\n",
    ">\"rig the election\"<br/>\n",
    ">\"to cost an awful lot of money”<br/>\n",
    ">\"travailler plus pour gagner plus”<br/>\n",
    "\n",
    "On dit que le sens du tout est plus grand que le sens de la somme de ses parties (*the meaning of the whole is greater than the meaning of the sum of its parts*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trouver des collocations à partir des n-grammes revient à calculer un **score** d'intérêt relatif à la présence de ces n mots ensemble. Ce score peut être calculé de différentes manières, par ex. :\n",
    "\n",
    "- Pointwise Mutual Information (PMI)\n",
    "- C-Value\n",
    "- etc.\n",
    "\n",
    "A noter que la PMI peut être utilisée pour calculer la collocation de mots qui ne se suivent pas forcément mais apparaissent dans le même contexte (par ex. la phrase ou le document)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise Mutual Information\n",
    "\n",
    "$$PMI(w_1, w_2) = \\log\\frac{p(w_1w_2)}{p(w_1)p(w_2)}$$\n",
    "\n",
    "avec : \n",
    "\n",
    "$p(w_1, w_2)$ la probabilité d'observer $w_1$ avec $w_2$ dans le corpus (*evidence*)<br/>\n",
    "$p(w_1)p(w_2)$ la probabilité d'observer $w_1$ avec $w_2$ par chance si les événements étaient indépendants\n",
    "\n",
    "En général, on utilise la valeur empirique pour estimer ces probabilités :\n",
    "\n",
    "$p(t) \\approx\\ \\frac{\\#t}{N}$\n",
    "\n",
    "si $\\#t$ est le nombre de fois où le terme est observé et $N$ le nombre de documents dans le corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La PMI pose certains problèmes, en particulier le fait d'être sensible aux motifs très rares. A contrario, un motif composé de mots fréquents peut finir par être supprimé car la valeur sera trop faible.\n",
    "\n",
    "Une solution à ce problème consiste à lisser la distribution de probabilité (par ex. avec un lissage de Laplace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.97\n",
      "9.97\n",
      "13.29\n"
     ]
    }
   ],
   "source": [
    "# quelques exemples\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "print('%0.2f' % bigram_measures.pmi(10, (10, 100), 100000))\n",
    "print('%0.2f' % bigram_measures.pmi(1, (10, 10), 100000))\n",
    "print('%0.2f' % bigram_measures.pmi(1, (1, 10), 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-value\n",
    "\n",
    "La C-value est une alternative à la PMI qui prend en compte l'écart relatif entre la fréquence d'un n-gramme et celui des (n-1)-gramme qui le composent.\n",
    "\n",
    "<img src=\"img/c-value.png\" style='height: 200px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie *nltk* propose des algorithmes efficaces pour extraire des collocations en calculant un certain nombre de mesures (PMI, *likelihood ratio*, chi2...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "list_tokens = word_tokenize(\" \".join(texte_docs))\n",
    "\n",
    "# word_tokenize() se base sur le Penn Treebank en anglais\n",
    "# une alternative est wordpunct_tokenize() qui utilise une expression régulière : \\w+|[^\\w\\s]+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(list_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons afficher le résultat avec le score associé, ici uniquement les bigrammes avec la fréquence associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', '``') : 0.0150 \n",
      "('.', \"''\") : 0.0098 \n",
      "(',', \"''\") : 0.0082 \n",
      "(\"''\", '``') : 0.0073 \n",
      "('.', '.') : 0.0066 \n",
      "('said', '.') : 0.0062 \n",
      "('of', 'the') : 0.0053 \n",
      "('?', \"''\") : 0.0045 \n",
      "('.', 'The') : 0.0042 \n",
      "('.', 'He') : 0.0035 \n",
      "('in', 'the') : 0.0033 \n",
      "(',', 'the') : 0.0028 \n",
      "('``', 'I') : 0.0026 \n",
      "(':', '``') : 0.0025 \n",
      "(\"''\", 'the') : 0.0023 \n",
      "('to', 'the') : 0.0023 \n",
      "(\"''\", 'Paul') : 0.0023 \n",
      "(',', 'and') : 0.0020 \n",
      "('``', 'You') : 0.0019 \n",
      "('!', \"''\") : 0.0017 \n",
      "('.', 'She') : 0.0017 \n",
      "(',', 'but') : 0.0017 \n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(finder.score_ngrams(bigram_measures.raw_freq)):\n",
    "    (c, v) = t\n",
    "    print(\"{} : {:.4f} \".format(c, v))\n",
    "    if i>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce qui suit, $nbest(m, k)$ affiche les $k$ termes qui optimisent la mesure $m$ et *apply_freq_filter(s)* permet de supprimer tous les termes qui apparaissent moins de $s$ fois dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', '``'),\n",
       " ('.', \"''\"),\n",
       " (',', \"''\"),\n",
       " (\"''\", '``'),\n",
       " ('.', '.'),\n",
       " ('said', '.'),\n",
       " ('of', 'the'),\n",
       " ('?', \"''\"),\n",
       " ('.', 'The'),\n",
       " ('.', 'He')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Helen', 'Mohiam'),\n",
       " ('Shaddam', 'IV'),\n",
       " ('Wan', 'na'),\n",
       " ('Missionaria', 'Protectiva'),\n",
       " ('gom', 'jabbar'),\n",
       " ('Salusa', 'Secundus'),\n",
       " ('ducal', 'signet'),\n",
       " ('per', 'cent'),\n",
       " ('CHOAM', 'Company'),\n",
       " ('Lisan', 'al-Gaib')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.apply_freq_filter(10)\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire de même pour les trigrammes, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bene', 'Gesserit', 'witch'),\n",
       " ('cleared', 'his', 'throat'),\n",
       " ('Baron', 'Vladimir', 'Harkonnen'),\n",
       " ('=', '=', '='),\n",
       " ('Bene', 'Gesserit', 'training'),\n",
       " ('Water', 'of', 'Life'),\n",
       " ('old', 'Reverend', 'Mother'),\n",
       " ('O.C', '.', 'Bible'),\n",
       " ('the', 'Missionaria', 'Protectiva'),\n",
       " ('the', 'Shield', 'Wall')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder_tri = TrigramCollocationFinder.from_words(list_tokens)\n",
    "finder_tri.apply_freq_filter(10)\n",
    "finder_tri.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction *apply_ngram_filter()* permet de créer ses propres filtres, par ex. basés sur un certain mot-clef :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harkonnen', 'bondsmen', 'endured'),\n",
       " ('Six', 'Harkonnen', 'bravos'),\n",
       " ('Harkonnen', 'defensive', 'sector'),\n",
       " ('evade', 'Harkonnen', 'restrictions'),\n",
       " ('adopt', 'Harkonnen', 'methods'),\n",
       " ('Bashar', 'Abulurd', 'Harkonnen'),\n",
       " ('Harkonnen', 'mercenaries', 'disguised'),\n",
       " ('Harkonnen', 'genetic', 'marker'),\n",
       " ('Harkonnen', 'troopers', 'maneuvered'),\n",
       " ('Harkonnen', 'orange', 'pennant')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder_tri = TrigramCollocationFinder.from_words(list_tokens)\n",
    "\n",
    "my_filter = lambda *w: 'Harkonnen' not in w\n",
    "finder_tri.apply_ngram_filter(my_filter)\n",
    "finder_tri.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple d'application au topic modeling\n",
    "\n",
    "<img src=\"img/labeling.png\" style='height: 500px'/>\n",
    "\n",
    "*Regrouper les données textuelles et nommer les groupes à l'aide de classes recouvrantes (Rizoiu et al., 2010).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques résultats :\n",
    "\n",
    "<img src=\"img/res_labeling.png\" style='height: 300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au passage, nous avons fait l'observation suivante :\n",
    "\n",
    "<img src=\"img/obs.png\" style='height: 300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin :\n",
    "\n",
    "Sur l'extraction de collocations avec la librairie NLTK :\n",
    "http://www.nltk.org/howto/collocations.html\n",
    "\n",
    "Sur le lien entre les features issus de nltk (notamment les collocations) et scikit-learn :\n",
    "http://www.nltk.org/_modules/nltk/classify/scikitlearn.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "* Lewis, David D. \"An evaluation of phrasal and clustered representations on a text categorization task.\" Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval. 1992.\n",
    "* M.A. Rizoiu, J. Velcin, J.H. Chauchat. Regrouper les données textuelles et nommer les groupes à l'aide de classes recouvrantes. Actes des 10ème journées francophones en Extraction et Gestion des Connaissances (EGC), Hammamet, Tunisie, 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
