{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Master Informatique, parcours Data Mining\n",
    "\n",
    "### Carnets de note Python pour le cours de Text Mining\n",
    "\n",
    "Julien Velcin, laboratoire ERIC, Université Lyon 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Représentation des documents (partie 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous allons voir :\n",
    "\n",
    "* Considérations générales\n",
    "* Modèle du sac de mots (*bag of words*) et matrice Documents x Termes\n",
    "* Extraire des caractéristiques (tokenisation, prétraitements)\n",
    "* Schémas de pondération (TF, TFxIDF...)\n",
    "* Comparer deux textes\n",
    "* Application : construire son propre moteur de recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Considérations générales\n",
    "\n",
    "Il existe differentes manières de représenter des données textuelles :\n",
    "\n",
    "- Chaîne de caractères (string)\n",
    "- Bag-of-Words (BoW)\n",
    "- Vector Space Model (VSM)\n",
    "- Séquence de mots\n",
    "- Ajouter des méta-données (par ex. catégories grammaticales)\n",
    "- Représentations plus complexes : arbres syntaxiques, graphes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Chaque représentation implique une manière différente de *comparer* les documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Un exemple très simple\n",
    "\n",
    "*\"John Doe has bought an apple.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Point de vue linguistique:\n",
    "\n",
    "<table style=\"border:0;\">\n",
    "<tr style=\"border:0;\">\n",
    "<td style=\"border:0; white-space:pre; padding:0 100px 0 0px;\">\"John Doe has bought an apple.\"</td>\n",
    "<td style=\"border:0;\"><img src=\"img/syntaxtree.png\" style='height: 150px'/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Point de vue statistique :\n",
    "\n",
    "<img src=\"img/bow-illu.png\" style='height: 150px'/>\n",
    "\n",
    "<table style=\"border:0;\">\n",
    "<tr style=\"border:0;\">\n",
    "<td style=\"border:0; white-space:pre; padding:0 100px 0 0px;\">\"John Doe has bought an apple.\"</td>\n",
    "<td style=\"border:0;\">{ apple,<br/><br/> bought,<br/><br/>John_Doe } </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/bow.png\" style='height: 400px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut déjà observer des problèmes évidents, tel que :\n",
    "\n",
    "*\"Mary asked Fred out.\"*\n",
    "<br/>\n",
    "*\"Fred asked Mary out.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La représentation est la même :\n",
    "<img src=\"img/mary.png\" style='height: 200px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A partir d'un *ensemble* de documents, on souhaite obtenir l'objet suivant :\n",
    "<img src=\"img/termdocmatrix.png\" style='height: 300px'/>\n",
    "ou sa transposée : la matrice Documents x Termes :\n",
    "<img src=\"img/doctermmatrix.png\" style='height: 300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Par exemple :\n",
    "<img src=\"img/termdocmatrix-2.jpg\" style='width: 400px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extraire les caractéristiques des textes avec le modèle \"sac de mots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En pratique, on utilise le formalisme du \"sac de mots\" et on suit plusieurs étapes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"img/bag_of_words.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Prenons à présent deux documents, tels que :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = [\"Some say the world will end in fire,\",\n",
    "     \"Some say in ice.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "La librairie contient une fonction qui permet de \"vectoriser\" un ensemble de textes en prenant en compte un certain nombre de prétraitements (*preprocessing*) couramment employés : mis en minuscule, utilisation de mots-outils, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observons le vocabulaire automatiquement construit à partir de ces deux textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'some': 5,\n",
       " 'say': 4,\n",
       " 'the': 6,\n",
       " 'world': 8,\n",
       " 'will': 7,\n",
       " 'end': 0,\n",
       " 'in': 3,\n",
       " 'fire': 1,\n",
       " 'ice': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une illustration bien utile, tirée de : Natural Language Processing in Action: Understanding, analyzing, and generating text with Python, par Hobson Lane, Cole Howard, Hannes Hapke, 2019, ISBN 9781617294631 (https://www.manning.com/books/natural-language-processing-in-action) :\n",
    "\n",
    "<img src=\"img/process.jpg\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrice documents x termes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut maintenant construire la matrice documents * termes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_bag_of_words = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Jetons un oeil au contenu de la matrice :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On observe que la valeur indiquée dans une cellule est le nombre d'occurrences d'un terme dans un document (TF pour *Term Frequency*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut également retrouver le nom des termes du vocabulaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\libas\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['end', 'fire', 'ice', 'in', 'say', 'some', 'the', 'will', 'world']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut retrouver les attributs (features) utilisés dans les documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['end', 'fire', 'in', 'say', 'some', 'the', 'will', 'world'],\n",
       "       dtype='<U5'),\n",
       " array(['ice', 'in', 'say', 'some'], dtype='<U5')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(X_bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Représentation TFxIDF\n",
    "A la place du nombre d'occurrences (TF), on peut utiliser une autre mesure qui prend en compte la rareté d'un mot dans le corpus :\n",
    "\n",
    "$$ tf_{t,d} \\times idf_{t} $$\n",
    "\n",
    "avec $tf_{t,d}$ le nombre d'occurrences de $t$ dans $d$\n",
    "\n",
    "et $idf_{t} = \\log \\frac{N}{df_t}$ ($N$ est le nombre total de documents ; $df_t$ nombre de documents où le terme apparaît)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "X_TFxIDF = tfidf_vectorizer.transform(X)\n",
    "print(X_TFxIDF.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe d'autres systèmes de pondération, en particulier lorsque des classes sont fournies :\n",
    "\n",
    "- Residual IDF (Rennie and Jaakkola, 2005)\n",
    "- Odds Ratio (Mladenic and M. Grobelnik, 2009)\n",
    "- Information Gain (Yang and Pedersen, 1997)\n",
    "- Chi-squared (Yang and Pedersen, 1997)\n",
    "- OKAPI BM25 (Robertson et al., 1994)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OKAPI BM25\n",
    "\n",
    "$$w_{BM25}(t,d) = tf_{BM25}(t,d) \\times idf_{BM25}(t)$$\n",
    "\n",
    "avec :\n",
    "\n",
    "$tf_{BM25}(t,d) = \\frac{tf(t,d) \\times (k_1 + 1)}{tf(t,d) + k_1 \\times (1 - b + b \\times dl(d) / dl_{avg})}$\n",
    "\n",
    "$idf_{BM25}(t) = \\log \\frac{N - df(t) + 0.5}{df(t) + 0.5}$\n",
    "\n",
    "où $dl(d)$ = longueur de d, $dl_{avg}$ = longueur moyenne<br/>\n",
    "$k_1$ et $b$ sont des constates données à priori (en général, $k_1=2$ et $b=0.75$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparaison de deux textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Les distances usuelles (ex. euclidenne) ne sont pas adaptées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dans les espaces à **beaucoup de dimensions** :\n",
    "\n",
    "Pourquoi les banquiers n'ont jamais de lingots sphériques ?\n",
    "\n",
    "Pourquoi les marchands d'oranges occupent beaucoup de place pour empiler peu d'oranges ?\n",
    "\n",
    "http://www.brouty.fr/Maths/sphere.html (see \"Curiosités du calcul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Malédiction de la dimension (curse of dimensionality)\n",
    "\n",
    "Richard E. Bellman (1920-1984): les hypervolumes sont presque vides!\n",
    "\n",
    "<img src=\"img/curse.png\" style='height: 400px'/>\n",
    "\n",
    "Un volume avec $dim=d$ a besoin de $10^d$ données pour peupler équitablement l'espace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Produit scalaire et cosinus\n",
    "\n",
    "$\\vec{x}$ et $\\vec{y}$ sont deux vecteurs dans le VSM.\n",
    "\n",
    "Cosine est une mesure de **similarité** calculée sur l'angle formé par les deux vecteurs :\n",
    "\n",
    "$$cos(\\vec{x},\\vec{y}) = \\frac{\\vec{x}.\\vec{y}}{||\\vec{x}||_2 \\times ||\\vec{y}||_2}$$\n",
    "\n",
    "Elle prend une valeur entre 0 (rien en commun) et 1 (même vecteurs à une constante près)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Interprétation géométrique\n",
    "\n",
    "<img src=\"img/cosine.png\" style='height: 300px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exemple : distribution des mots les plus fréquents dans Harry Potter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Commençons par lire les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(os.path.join(\"datasets\", \"Harry_Potter_1.txt\")) as f:\n",
    "    lines = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ajouter un filtre pour retirer les mots trop fréquents (on ne va pas le faire pour le moment) et les mots trop rares (comme les *hapax*, càd les mots qui n'apparaissent qu'une seule fois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# penser à rajouter les options du vectorizer : supprimer les mots trop rares/fréquents, contrôler la taille du vocabulaire\n",
    "tf_vectorizer = CountVectorizer(stop_words=\"english\",  max_df=1.0, min_df=1, max_features=None)   \n",
    "#tfidf_vectorizer = TfidfVectorizer()\n",
    "tf_vectorizer.fit(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 5442\n"
     ]
    }
   ],
   "source": [
    "# montrer l'intégralité du vocabulaire (peut être long) :\n",
    "#tf_vectorizer.vocabulary_\n",
    "print(\"Taille du vocabulaire : {}\".format(len(tf_vectorizer.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_hp = tf_vectorizer.transform(lines)\n",
    "features_hp = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à noter qu'on peut directement faire le fit + transform :\n",
    "X_hp = tf_vectorizer.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On peut utiliser quelques fonctions pour afficher le vecteur pour un document en particulier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# des options permettent de limiter (ou non) le nombre de lignes/colonnes affichées\n",
    "# par exemple :\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "def top_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids if row[i]>0]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    if len(top_feats) > 0:\n",
    "        df.columns = ['feature', 'score']\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_feats(row, features, top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn’t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn’t want Dudley mixing with a child like that.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>potters</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mrs</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sister</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>didn</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dursleys</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>think</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dursley</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>possible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neighbors</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fact</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>arrived</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>keeping</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hadn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>boy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>undursleyish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wanted</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>met</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>like</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>potter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>son</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>small</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>discover</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>somebody</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>shuddered</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dudley</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>seen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>greatest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>reason</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>say</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mixing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>husband</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>child</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>knew</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>away</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pretended</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>secret</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  score\n",
       "0        potters      4\n",
       "1            mrs      3\n",
       "2         sister      3\n",
       "3           didn      3\n",
       "4       dursleys      3\n",
       "5          think      2\n",
       "6           good      2\n",
       "7        dursley      2\n",
       "8       possible      1\n",
       "9          years      1\n",
       "10     neighbors      1\n",
       "11          fact      1\n",
       "12       arrived      1\n",
       "13       keeping      1\n",
       "14          hadn      1\n",
       "15           boy      1\n",
       "16          want      1\n",
       "17  undursleyish      1\n",
       "18        wanted      1\n",
       "19           met      1\n",
       "20          bear      1\n",
       "21          like      1\n",
       "22        potter      1\n",
       "23           son      1\n",
       "24         small      1\n",
       "25      discover      1\n",
       "26      somebody      1\n",
       "27     shuddered      1\n",
       "28        dudley      1\n",
       "29          seen      1\n",
       "30          fear      1\n",
       "31      greatest      1\n",
       "32        reason      1\n",
       "33           say      1\n",
       "34        mixing      1\n",
       "35       husband      1\n",
       "36         child      1\n",
       "37          knew      1\n",
       "38          away      1\n",
       "39     pretended      1\n",
       "40        street      1\n",
       "41        secret      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lines[6])\n",
    "\n",
    "#top_feats_in_doc(X_hp, features_hp, 4, top_n=30)\n",
    "top_feats_in_doc(X_hp, features_hp, 6, top_n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les mots les plus fréquents :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, on va passer par une représentation non creuse du tableau, ce qui est **une très mauvaise idée** dans le cas général où les données sont en très grande dimension. Le mieux est de passer par les méthodes de la librairie *csr_matrix*. \n",
    "\n",
    "#float(X_hp[0,].dot(X_hp[0,].transpose()).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harry</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ron</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hagrid</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hermione</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>know</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>didn</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>got</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>like</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ve</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>professor</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>just</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>don</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>snape</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>looked</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ll</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dumbledore</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dudley</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>going</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>malfoy</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>right</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>look</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>think</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>yeh</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>uncle</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  score\n",
       "0        harry   1326\n",
       "1         said    794\n",
       "2          ron    429\n",
       "3       hagrid    370\n",
       "4     hermione    270\n",
       "5         know    214\n",
       "6         didn    199\n",
       "7          got    199\n",
       "8         like    193\n",
       "9           ve    182\n",
       "10   professor    180\n",
       "11        just    180\n",
       "12         don    175\n",
       "13       snape    171\n",
       "14      looked    169\n",
       "15          ll    162\n",
       "16  dumbledore    160\n",
       "17      dudley    140\n",
       "18       going    135\n",
       "19      malfoy    128\n",
       "20       right    127\n",
       "21        look    126\n",
       "22       think    123\n",
       "23         yeh    122\n",
       "24       uncle    122"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = X_hp.toarray()\n",
    "\n",
    "n_docs, n_terms = D.shape\n",
    "\n",
    "#tf_means = np.mean(D, axis=0)\n",
    "tf_sum = np.sum(D, axis=0)\n",
    "tff = top_feats(tf_sum, features_hp)\n",
    "tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Mot les plus fréquents'}, xlabel='mot'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_f = tff.feature\n",
    "top_v = tff.score\n",
    "df = pd.DataFrame({'mot':top_f, 'TF':top_v})\n",
    "df.plot.bar(x='mot', y='TF', rot=90, title =\"Mot les plus fréquents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Comparer des documents revient à comparer les valeurs de deux colonnes (vecteurs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# fonction calculant le cosinus entre deux vecteurs\n",
    "def cosinus(i, j):\n",
    "    num = np.dot(i, j)\n",
    "    den = math.sqrt(sum(i*i))*math.sqrt(sum(j*j))\n",
    "    if (den>0):    \n",
    "        return (num/den)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature  score\n",
      "0     dursley      2\n",
      "1        neck      2\n",
      "2      called      2\n",
      "3      blonde      1\n",
      "4       twice      1\n",
      "5   neighbors      1\n",
      "6    dursleys      1\n",
      "7       beefy      1\n",
      "8   grunnings      1\n",
      "9        came      1\n",
      "10     nearly      1\n",
      "11      finer      1\n",
      "12        man      1\n",
      "13      spent      1\n",
      "14     fences      1\n",
      "15      usual      1\n",
      "16   mustache      1\n",
      "17    opinion      1\n",
      "18       time      1\n",
      "19        mrs      1\n",
      "20         mr      1\n",
      "21     hardly      1\n",
      "22   director      1\n",
      "23        son      1\n",
      "24      small      1\n",
      "25      large      1\n",
      "26     garden      1\n",
      "27        did      1\n",
      "28       firm      1\n",
      "29        boy      1\n",
      "30     spying      1\n",
      "31        big      1\n",
      "32     useful      1\n",
      "33     dudley      1\n",
      "34    craning      1\n",
      "35     drills      1\n",
      "     feature  score\n",
      "0     number      1\n",
      "1    dursley      1\n",
      "2       tyke      1\n",
      "3   chortled      1\n",
      "4        car      1\n",
      "5     little      1\n",
      "6       left      1\n",
      "7         mr      1\n",
      "8      house      1\n",
      "9     backed      1\n",
      "10     drive      1\n",
      "11       got      1\n"
     ]
    }
   ],
   "source": [
    "print(top_feats_in_doc(X_hp, features_hp, 5, top_n=40))\n",
    "print(top_feats_in_doc(X_hp, features_hp, 10, top_n=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12909944487358058"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosinus(D[5, :], D[10, :])\n",
    "#cosinus(D[5, :], 10*D[10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créer son propre moteur de recherche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer son propre moteur de recherche maison, la procédure revient à :\n",
    "\n",
    "* construire un pseudo-document correspondant à la requête, càd un vecteur-requête dans le même espace que les documents\n",
    "* comparer le vecteur-requête avec tous les vecteurs documents (càd les lignes de la matrice), par ex. avec une mesure cosinus\n",
    "* trier le vecteur des scores qui en résultent\n",
    "* afficher les documents qui ont obtenu les meilleurs scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3491, 1355, 1401]\n"
     ]
    }
   ],
   "source": [
    "query = ['privet', 'drive', 'dursley']\n",
    "#query = ['harry', 'wand']\n",
    "\n",
    "#query = ['1473', 'aaaaarrrgh']\n",
    "\n",
    "indexes = [features_hp.index(q) for q in query if q in features_hp]\n",
    "  # index permet de trouver le numéro correspondant aux mots dans le vocabulaire\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit un vecteur de la même taille que le vocabulaire. Il est initialisé à zéro, puis on y met la valeur 1 pour les termes de la requête.\n",
    "\n",
    "De manière alternative, on pourrait mettre un poids aux mots de la requête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = np.zeros(n_terms)\n",
    "query_vec[indexes] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query_vec[5184-10:5184+10]\n",
    "query_vec[3491-10:3491+10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier que le vecteur requête contient bien 3 éléments non nuls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(query_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du cosinus vis-à-vis de la requête pour 1 document :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3872983346207417"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosinus(D[4, :], query_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On automatise en calculant pour tous les docs et on triant le résultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui crée un dictionnaire associant le cosinus à chaque document\n",
    "# puis le trie de manière décroissante\n",
    "\n",
    "def search(q, D):\n",
    "    cc = {i: cosinus(D[i, :], q) for i in range(n_docs)}\n",
    "    cc = sorted(cc.items(), key=lambda x: x[1], reverse=True)\n",
    "    return cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search(query_vec, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(253, 0.8164965809277259),\n",
       " (41, 0.47140452079103173),\n",
       " (420, 0.40824829046386296),\n",
       " (11, 0.3931785497463924),\n",
       " (4, 0.3872983346207417),\n",
       " (10, 0.33333333333333337),\n",
       " (34, 0.33333333333333337),\n",
       " (305, 0.3086066999241839),\n",
       " (45, 0.28867513459481287),\n",
       " (24, 0.2581988897471611)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne retient que les dix premiers résultats (par exemple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[253, 41, 420, 11, 4, 10, 34, 305, 45, 24]\n"
     ]
    }
   ],
   "source": [
    "nb_top_docs = 10\n",
    "top_docs = [r for (r,v) in result[0:nb_top_docs]]\n",
    "print(top_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir, on peut afficher les textes les plus pertinents pour la requête :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (253): 4 Privet Drive\n",
      "2 (41): He didn’t say another word on the subject as they went upstairs to bed. While Mrs. Dursley was in the bathroom, Mr. Dursley crept to the bedroom window and peered down into the front garden. The cat was still there. It was staring down Privet Drive as though it were waiting for something.\n",
      "3 (420): “DURSLEY!” he boomed.\n",
      "4 (11): It was on the corner of the street that he noticed the first sign of something peculiar — a cat reading a map. For a second, Mr. Dursley didn’t realize what he had seen — then he jerked his head around to look again. There was a tabby cat standing on the corner of Privet Drive, but there wasn’t a map in sight. What could he have been thinking of? It must have been a trick of the light. Mr. Dursley blinked and stared at the cat. It stared back. As Mr. Dursley drove around the corner and up the road, he watched the cat in his mirror. It was now reading the sign that said Privet Drive — no, looking at the sign; cats couldn’t read maps or signs. Mr. Dursley gave himself a little shake and put the cat out of his mind. As he drove toward town he thought of nothing except a large order of drills he was hoping to get that day.\n",
      "5 (4): Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.\n",
      "6 (10): “Little tyke,” chortled Mr. Dursley as he left the house. He got into his car and backed out of number four’s drive.\n",
      "7 (34): “So?” snapped Mrs. Dursley.\n",
      "8 (305): He was going to wait for the postman on the corner of Privet Drive and get the letters for number four first. His heart hammered as he crept across the dark hall toward the front door —\n",
      "9 (45): Mr. Dursley might have been drifting into an uneasy sleep, but the cat on the wall outside was showing no sign of sleepiness. It was sitting as still as a statue, its eyes fixed unblinkingly on the far corner of Privet Drive. It didn’t so much as quiver when a car door slammed on the next street, nor when two owls swooped overhead. In fact, it was nearly midnight before the cat moved at all.\n",
      "10 (24): “Shoo!” said Mr. Dursley loudly.\n"
     ]
    }
   ],
   "source": [
    "for i, td in zip(range(nb_top_docs), top_docs):\n",
    "    #print(top_feats_in_doc(X_hp, features_hp, td))\n",
    "    print(\"%s (%s): %s\" % (i+1, td, lines[td]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, notez que la matrice construite par *scikit-learn* est une structure dédiée aux matrices creuses provenant de la librairie *scipy* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est donc possible de travailler directement avec cette librairie afin d'éviter de passer par une représentation pleine gourmande en mémoire (càd éviter le recours à toarray() de numpy).\n",
    "\n",
    "Exemple du produit scalaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hp[4, :].dot(query_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques éléments d'évaluation\n",
    "\n",
    "L'objectif consiste à comparer une \"vérité terrain\" constituée d'un ensemble ou d'une liste ordonnée de réponses idéales avec la sortie proposée par le moteur de recherche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $E$ = liste attendue des documents pertinents (E pour *Expected*) et $O$ = sortie de l'algorithme de recherche (O pour *Output*) :\n",
    "<img src=\"img/evaluation.png\" style='height: 200px'/>\n",
    "précision : P = $| E \\cap O | / |O|$<br/>\n",
    "rappel (*recall*) : R = $| E \\cap O | / |E|$<br/>\n",
    "F-mesure : FM = $2 (P\\times R) / (P + R)$<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
